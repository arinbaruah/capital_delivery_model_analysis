---
title: "Enhancing Future Capital Delivery: A Comparative analysis of Melbourne Water Corporation's Project Models"
author:
- name: Arindom Baruah
  degrees: Master of Business Analytics, Monash University
  email: abar0090@student.monash.edu
  
email: BusEco-Econometrics@monash.edu
organization: Monash University, Melbourne Water Corporation
bibliography: references.bib
execute: 
  echo: false
format: report-pdf
toc: true
header-includes:
  - \usepackage{tcolorbox}
  - \newtcolorbox{noteBox}{colback=yellow!5!white, colframe=yellow!50!black, title=Note}
  - \newtcolorbox{warningBox}{colback=red!5!white, colframe=red!50!black, title=Limitation}
  - \newtcolorbox{tipBox}{colback=green!5!white, colframe=green!50!black, title=Tip}
  - \newtcolorbox{confBox}{colback=red!5!white, colframe=red!5!black, title=Confidentiality statement}
---


```{r}
#| echo: false
library(tidyverse)
library(ggthemes)
library(kableExtra)
library(tibble)
library(lubridate)
library(janitor)
library(fpp3)
library(ggrepel)
library(patchwork)
```



\newpage
# List of abbreviations and terminologies

The analysis report will use numerous abbreviations and terminologies at various stages. This section will serve as a reference for what do these abbreviations mean alongwith their definitions.

1. __BNI (Business Need Identifier)__ : A date on which a project concept is first conceived
2. __PBC (Preliminary Business Case)__ : A date on which the first business case is submitted
3. __BCA__ : A date on which the business case is approved and the project  
4. __Stage 1__ : A date on which the first stage of practical completion of project is reached
5. __Stage 2__ : A date on which the second stage of practical completion of project is reached
6. __Stage 3__ : A date on which the defect detection period of project is reached
7. __FFC (Final Forecast Cost)__ : An estimate of the total valuation of the project in dollar value
8. __ID__ : Unique identification for each individual project
9. __Owner group__ : The division within Melbourne Water Corporation responsible for completing the particular project
10. __Delivery Program__ : The classification of the project based on the capital delivery program framework
11. __PS (Price Submission)__ : Pricing submission period for Melbourne Water's business case to be submitted to Department of Treasury and Finance (DTF) 
12. __CDM (Capital Delivery Model)__: The Capital Delivery Model is a set of frameworks that allows Melbourne Water to efficiently delegate the design or construction activities to the third party service provider by accounting for the type of project, cost of project and the risks associated with the project.
13. __Owner Team__ : The subdivision within Melbourne Water Corporation responsible for completing the project 


\newpage

# Executive Summary

The goal of this study is to outline the methodology and guidelines for conducting the Capital Delivery Model project data analysis. This analysis aims to develop a reproducible framework that compares the current delivery model with past models, providing valuable insights to enhance the future delivery model planned for years between 2026 to 2031, and potentially use these learnings for future periods.

For the purpose of the current analysis, Melbourne Water Corporation's project data with business need identifier (BNI) dates between 2016 to 2024 were analysed. The major areas of study for the current analysis are delineated as follows:

1.	__Distribution of Projects by Delivery Model:__ Insights gained through the examination of projects categorized by delivery model and delivery programs. 
2.	__Implication of the distribution of projects on overall project valuations:__ Analysis of the number of projects associated with each delivery model alongwith their subsequent cost valuations, thereby providing a range of potential outcomes and expectations for the new delivery model. 
3.	__Project Duration Analysis:__ Investigation of project durations relative to their overall valuations. 
4.	__Approval Duration Distribution:__ Assessment of the time required for project approvals across different various delivery programs and critical project stages. 
5.	__Future Project Forecast:__ Estimation of the number of projects anticipated in the delivery period from 2026 to 2031. 

By systematically examining past and present performance, the aim is to identify key trends, strengths, and areas for improvement, ensuring that future projects are executed more efficiently and effectively. 


```{r read-data}
project_data <- read_csv("data/Capital_Deliver_Project_deidentified.csv")
project_data <- clean_names(project_data)
```

```{r date-format}

project_data<- project_data %>%
  mutate(bni = sapply(strsplit(as.character(bni), " "), `[`, 1)) # Cleaning BNI dates

project_data<- project_data %>%
  mutate(bni = str_replace_all(bni, "/", "-")) # Reformatting BNI dates

project_data<- project_data %>% 
  mutate(bca = sapply(strsplit(as.character(bca), " "), `[`, 1)) # Cleaning BCA dates

project_data<- project_data %>% 
  mutate(pbc = sapply(strsplit(as.character(pbc), " "), `[`, 1)) # Cleaning PBC dates

project_data<- project_data %>%
  mutate(pbc = str_replace_all(pbc, "/", "-")) # Reformatting PBC dates

project_data<- project_data %>% 
  mutate(stage1 = sapply(strsplit(as.character(stage1), " "), `[`, 1)) # Cleaning PBC dates

project_data<- project_data %>% 
  mutate(stage2 = sapply(strsplit(as.character(stage2), " "), `[`, 1)) # Cleaning PBC dates

project_data<- project_data %>% 
  mutate(stage3 = sapply(strsplit(as.character(stage3), " "), `[`, 1)) # Cleaning PBC dates
  

```


```{r}
# Reformatting the dates into machine-readable form

project_data$pbc <- as.Date(project_data$pbc, format = "%d-%m-%Y")
project_data$bni <- as.Date(project_data$bni, format = "%d-%m-%Y")
project_data$bca <- as.Date(project_data$bca, format = "%Y-%m-%d") # Opposite to above format
project_data$stage1 <- as.Date(project_data$stage1, format = "%Y-%m-%d") 
project_data$stage2 <- as.Date(project_data$stage2, format = "%Y-%m-%d")
project_data$stage3 <- as.Date(project_data$stage3, format = "%Y-%m-%d")

```

```{r}
project_subset_data <- project_data 

```



```{r}

# Create a variable for CDM
project_data <- project_data %>% mutate(cdm = case_when(year(bca) >= 2016 & year(bca) <= 2021 ~ "CDM-16",
                                                        year(bca) >= 2021 & year(bca) <= 2026 ~ "CDM-21",
                                                        .default = "CDM-26"))

# Create a variable for FFC bands
project_data <- project_data %>% mutate(ffc_band = case_when(
                                                             ffc >= 0 & ffc <= 5*10^6 ~ "< = 5",
                                                             ffc >= 5* 10^6 & ffc <= 10 * 10^6 ~ "5-10",
                                                             ffc >= 10* 10^6 & ffc <= 20 * 10^6 ~ "10-20",
                                                             ffc >= 20* 10^6 & ffc <= 50 * 10^6 ~ "20-50",
                                                             ffc >= 50* 10^6 & ffc <= 80 * 10^6 ~ "50-80",
                                                             ffc >= 80* 10^6 & ffc <= 1 * 10^9 ~ "> 80",
                                                        .default = NA))
# Create a variable to indicate project completion status

project_data <- project_data %>% mutate(status = if_else(stage1 <= today(),"Completed","Ongoing"))

```



```{r}
project_numbers <- project_subset_data %>% group_by(delivery_program,yearmonth(bca)) %>% summarise(Total = n())

project_tsibble <- project_numbers %>% # Tsibble created based on BCA year
   as_tsibble(index = `yearmonth(bca)`,key = delivery_program) %>% fill_gaps(Total = 0L) # Fill NA with 0

```

```{r}
project_numbers <- project_data %>% group_by(ffc_band,yearmonth(bca)) %>% summarise(Total = n())

project_numbers <- project_data %>% group_by(ffc_band,yearmonth(bca)) %>% summarise(Total = n())

project_tsibble <- project_numbers %>% # Tsibble created based on BCA year
   as_tsibble(index = `yearmonth(bca)`,key = ffc_band) %>% fill_gaps(Total = 0L) # Fill NA with 0

```




```{r}
#| eval: false

gg_subseries(project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)))

gg_season(project_tsibble %>% filter(ffc_band == "< = 5" & (`yearmonth(bca)` < ymd(20240601))))

ACF(project_tsibble %>% filter(ffc_band == "< = 5")) %>% autoplot()
```


```{r}
#| eval: false
# Example data

library(RColorBrewer)
data <- data.frame(
  Source = c("A", "A", "B", "B", "C", "C"),
  Target = c("X", "Y", "X", "Y", "Y", "Z"),
  Freq = c(10, 20, 15, 25, 5, 10)
)


project_group_progam <- project_data %>%
  group_by(ffc_band, cdm) %>%
  summarise(Total = sum(ffc)) %>%
  ungroup() %>%
  group_by(cdm) %>%
  mutate(Percentage = Total / sum(Total))


colors <- brewer.pal(n = length(unique(data$Source)), name = "Set2")

ggplot(data = data, aes(axis1 = Source, axis2 = Target, y = Freq)) +
  geom_alluvium(aes(fill = Source), color = "black") +
  geom_stratum() +
  geom_label(stat = "stratum", aes(label = after_stat(stratum)), size = 5, fill = "white", color = "black") +
  scale_fill_manual(values = colors) +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    legend.position = "none" # Hide the legend for a cleaner look
  ) +
  ggtitle("Enhanced Sankey Diagram Example")


ggplot(data = project_group_progam, aes(axis1 = ffc_band, axis2 = cdm, y = Total)) +
  geom_alluvium(aes(fill = cdm, color = "black")) +
  geom_stratum() +
  geom_label(stat = "stratum", aes(label = after_stat(stratum)), size = 5, fill = "white", color = "black") +
  #scale_fill_manual(values = colors) +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    legend.position = "none" # Hide the legend for a cleaner look
  ) +
  ggtitle("Enhanced Sankey Diagram Example")


library(dplyr)

# Sample data
data <- data.frame(
  Project = c('Project A', 'Project B', 'Project C', 'Project D', 'Project E'),
  Percentage = c(20, 15, 15, 10, 30),
  Cost = c(10, 5, 5, 2, 8)
)

# Sort data by Cost in descending order
data <- data %>%
  arrange(desc(Cost))

# Calculate cumulative percentage for cost
data <- data %>%
  mutate(CumulativeCost = cumsum(Cost) / sum(Cost) * 100)

library(ggplot2)

ggplot(data = data, aes(x = reorder(Project, -Cost), y = Cost)) +
  geom_bar(stat = "identity") +
  geom_line(aes(y = CumulativeCost * max(Cost) / 100, group = 1), color = "blue", size = 1) +
  scale_y_continuous(sec.axis = sec_axis(~ . * 100 / max(Cost), name = "Cumulative Percentage")) +
  labs(x = "Projects", y = "Costs", title = "Pareto Chart") +
  theme_minimal()
```


```{r}
dcmp <- project_tsibble |> filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)) |>
  model(stl = STL(Total ~ season(window = 11))) 
#components(dcmp) %>% autoplot()
```





```{r}

# Create a variable for CDM
project_data <- project_data %>% mutate(cdm = case_when(year(bca) >= 2016 & year(bca) <= 2021 ~ "CDM-16",
                                                        year(bca) >= 2021 & year(bca) <= 2026 ~ "CDM-21",
                                                        .default = "CDM-26"))

# Create a variable for FFC bands
project_data <- project_data %>% mutate(ffc_band = case_when(
                                                             ffc >= 0 & ffc <= 5*10^6 ~ "< = 5",
                                                             ffc >= 5* 10^6 & ffc <= 10 * 10^6 ~ "5-10",
                                                             ffc >= 10* 10^6 & ffc <= 20 * 10^6 ~ "10-20",
                                                             ffc >= 20* 10^6 & ffc <= 50 * 10^6 ~ "20-50",
                                                             ffc >= 50* 10^6 & ffc <= 80 * 10^6 ~ "50-80",
                                                             ffc >= 80* 10^6 & ffc <= 1 * 10^9 ~ "> 80",
                                                        .default = NA))
# Create a variable to indicate project completion status

project_data <- project_data %>% mutate(status = if_else(stage1 <= today(),"Completed","Ongoing"))

```






# Data Source

The data for the current analysis has been sourced from the “Estimating & Scheduling” PowerBI dashboard in the Major Program Delivery workspace at Melbourne Water Corporation. This dashboard draws this data from the Microsoft Project Online software which logs individual project data based on the inputs of the assigned project managers. The data was exported as a CSV file on 19th July, 2024 and as such, contains the latest updated project valuations up to that date. Due to the sensitive nature of the data, there is no public access to this data. 

\begin{confBox}

To comply with Melbourne Water Corporation’s confidentiality requirements, the data has been de-identified and includes only the relevant fields necessary for obtaining insights for the intended evaluation purpose.

\end{confBox}

# Limitations of the data {#sec-limit}

The limitations within the source of the data which may have affected the analysis are delineated as follows:

1. As the source file was exported from the Microsoft PowerBI organisational dashboard, certain fields such as the dates were not in their desirable format for the current analysis and were required to be converted into a machine-readable format.This was a critical step to perform the required exploratory data analysis and form the time-series data for forecasting purposes.

2. While the original dataset contains project data from 2008 to 2024, a recent software migration to the Microsoft Project Online platform has rendered the data for the period between 2008 and 2016 potentially unrepresentative. As a result, the current analysis utilizes data from 2016 to 2024. This period encompasses the two recent delivery model periods.

3. Multiple projects were observed to have empty PBC fields. This is likely due to the case where small scale projects tend to bypass one gate of approval to reduce approval duration. While this does not apply to all projects of similar nature, there is however no indicator in the data which allows for detection of such an event other than a missing date.

4. The dataset here is an observational data and in particular, a census data. Some of the limitations that are prevalent in such datasets are as follows :

   - Each row in the dataset is a project whose details are provided by an individual Project Manager. As a result, there may be non-uniformity in the data provided as each Project Manager may have their own interpretations of the data they may have provided.
   - The current dataset obtained is a subset of an observational data. These types of data are often plagued with lack of randomisation during the selection of data. This may lead to biases in the dataset such as selection and systematic bias.
   - The data maybe mis-classified or filled in non-uniform units by the various sources, leading to lack of accuracy of the overall dataset.


# Introduction

The construction of large-scale infrastructure projects, commonly referred to as “CAPEX” projects, is highly resource-intensive and typically requires effective collaboration among multiple organizations for successful and timely completion. @no2013specification suggests that in a collaborative work environment, teams are required to generate information using standardized procedures and agreed-upon standards and methods. This ensures consistency in form and quality, allowing the information to be used and reused without the need for modification or interpretation. However, in practice, such high level collaboration is often challenging and needs well laid communication as well as contractual frameworks for effective 

To initiate, monitor, and deliver these projects, a comprehensive framework is usually developed. This framework assesses the project’s valuation and associated risks, and then engages the appropriate service providers to ensure timely project delivery. This framework which governs the delivery route of a project is termed as the Capital Delivery Model.

Each Capital Delivery Model presides over a period of 5 years, after the completion of which, a new Capital Delivery Model initiates. Before the creation of such a model,the host organisation (in this case, Melbourne Water Corporation) is required to submit a proposal of projects to be delivered over the next 5 years to the Department of Treasury and Finance, Government of Australia. Once the list of projects are approved or amended, a Capital Delivery Model is then designed, analysed, iterated and improved over a course of a year, after which, it is finally released to the market, where service providers may decide to get into a partnership with Melbourne Water for delivering the next set of infrastructures.   

@garcia2021measuring states that a key underlying challenge in today’s model-driven approach to engineering is how progress and level of effort are being measured and reported. The goal of the current project is to quantify the key results of the past delivery models and obtain important insights which would allow for to design an improved capital delivery model for the upcoming pricing submission period between 2026-2031. In particular, the analysis would attempt to estimate the future number of projects and their expected valuations based on the distribution of projects in the current and past deliver models.

# Motivation of the current study

The process of estimating the mix of the type of projects expected in the new capital delivery model after the 2026 price submission is based on the analysis of the current delivery model (CDM 2021) and the previous delivery model (CDM 2016). The forthcoming 2026 price submission is projected to surpass recent submissions in value, presenting significant challenges in project management. This includes the engagement of service providers for construction, efficient management of key crew resources, and rigorous monitoring to ensure timely infrastructure delivery. The current data analysis review of the projects in CDM 2016 and CDM 2021 will provide an adequate baseline of the expected proportion of the major capital delivery projects based on valuation and duration expected in the future delivery model (CDM 2026), thereby providing insights and eventually aiding in the key decision making for creation of the frameworks.

The current analysis is performed by studying the following key parameters in the project data: \
      1.	Total final forecast cost (FFC) \
      2.	CDM period (2016, 2021 and 2026) \
      3.	Project duration across each stage \
      4.	Delivery Program\
      5.  Project labour hours in each delivery program 

# Objectives

The objectives and the scope of the analysis of the CDMs were defined through Melbourne Water fortnightly workshops and feedback as received from the project director and the steering group. These are delineated as follows:

  1. The analysis must clearly indicate the performance level of project deliveries for both the current CDM-21 and the previous CDM-16. This should primarily focus on the duration of the projects and highlight any notable changes in this aspect.
  2. Insights on the current and previous CDM must be able to provide a baseline for the estimated number of projects which can be expected in the future delivery model (CDM-26). These projections would allow for more informed decision making while building the contractual frameworks to engage service providers.
  3. A detailed analysis of the historical project data should indicate the proportion of projects requiring approval by each governing body. This will provide an estimation of the duration of projects from the BNI stage to the BCA stage for the new delivery model, enabling better resource management.
  
  
# Significance of the current study

Based on the numerous inputs from the project director and the steering group at Major Capital Delivery division in Melbourne Water, the the scope and significance for the current CDM data analysis project was finalised. These have been delineated as follows:  

  1.	The analysis must provide an estimate of the project breakdown for CDM-26 after the latest price submission in 2026 by taking the current delivery model (CDM-21) and the previous delivery model (CDM-16) as the reference point. The results of this study can be used as a basis for obtaining an informed prior information to design the new capital delivery model (CDM-26).
  2.	The analysis would supplement the decision making on effective selection of service providers for projects in the future delivery model based on the current distribution of the delivery programs across various FFCs and past CDMs.
  3.	The breakdown of the projects must allow a conservative estimate of the number of projects that would require approval at each level of authority, thereby indicating the approval duration for the project to be approved and initiated.
  4.	The analysis should aid in understanding how the proportions of projects in the future delivery model would differ from the benchmarks created by past models upon additional inputs.
  5.	Insights obtained from the total project duration and the average duration for the critical stages of each project may allow for effective project team planning.
  6.	The analysis must allow one to quickly detect outliers in the data and investigate these outliers further.
  7.  The study aims to develop a forecasting model capable of predicting the number of projects expected during a price-submission period. This model should continuously improve as more data is accumulated, potentially extending its applicability to future periods. By doing so, it is anticipated that the model will enable more efficient allocation of resources for future projects.


# Methodology

This section is dedicated for the purpose of explaining the detailed methodology of the data analysis performed to obtain the actionable insights that will be delineated later in @sec-results.

## Selection of projects for analysis

While the dataset contains the details for projects undertaken by the various divisions of Melbourne Water Corporation, for the purpose of the current analysis, only those projects which are delivered or expected to be delivered by the Major Capital Delivery division are considered. In particular, these are those projects which are delivered through a contractual framework, called as the "Water and Sewerage Program", engineering maintenance projects to keep current assets running, or in certain instances, large projects which are tendered in the open market for service providers to bid.

In the current dataset, these projects are those which come under the delivery programs as tabulated in @tbl-programs.

```{r}
#| label: tbl-programs
#| tbl-cap: "Major Capital Delivery programs"
#| tbl-pos: H
tibble(
  "Major Capital Delivery" = c("Major Works-Small scale", "Major Works-Framework",
                                        "Contestable", "Major Works-Open Market")
) %>%
  kable("latex") %>%
  kable_styling(latex_options = c("striped"), 
                full_width = FALSE, 
                position = "center") %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  row_spec(0, bold = TRUE) %>%  # Keep headers bold
  row_spec(1:4, font_size = 8)
```

As a result, while analysing the current data, projects with delivery programs matching the above list of programs are filtered.

## Assigning project to each capital delivery model

While the data contains key dates such as the BNI, PBC, BCA and stages 1-3, however, it is essential to assign each project into its respective capital delivery model. Although this data is not readily captured at the source, however, through a deeper understanding of the critical project dates, a logic can be devised that assigns each project to a categorical variable indicating the version of CDM this model was a part of.

The hierarchy of a project approval flowchart is illustrated through @fig-flowchart. This is a sequential process where the concept of a project is first identified and reported into the Project Online system on the BNI date. Once a project has been identified, a business case is prepared which undergoes an iterative process. The date of the first submitted business case is termed as the PBC. Once a project has been approved by the relevant Melbourne Water authority, the date is recorded as BCA. Stage 1 is the date on which the service provider claims that the project is now effectively "delivered". Special provisions within the contract as invoked by Melbourne Water with the service provider requires these two parties to collaborate together in order to repair any defects during the operation of the delivered infrastructure. This period typically ranges between 6 months to 1 year, post which, the project reaches its Stage 3 date and is now delivered in its entirety.

While selected projects may bypass some of the approval gates, however, this flowchart is generally true for all of Melbourne Water projects.

![Project approval gate flowchart](images/project_stage.png){#fig-flowchart}

For the purpose of assigning the delivery model to each of the projects, the BCA date is utilised as this is effectively the date when the project went live. On the other hand, the completion status of the project is determined based on whether the Stage 1 date is before or after the data export date. (19th July, 2024). @tbl-cdm tabulates the criteria utilised for assigning each project to a relevant CDM.

```{r}
#| label: tbl-cdm
#| tbl-cap: "Capital Delivery Model assignment criteria"
#| tbl-pos: H

tibble(
  "BCA Year" = c("2016 <= BCA < 2021", "2021 <= BCA < 2026"),
  "Capital Delivery Model" = c("CDM-16", "CDM-21")
) %>%
  kable("latex") %>%
  kable_styling(latex_options = c("striped"), 
                full_width = FALSE, 
                position = "center") %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  column_spec(2, bold = TRUE, color = "red") 
```

## Project completion status

For the purpose of the current analysis, a project is considered to be "delivered" or "completed" if its Stage 1 date is prior to the date on which, the data was exported. The export date in this case is __19th July, 2024__. The completion criteria is further tabulated through @tbl-completion. 

```{r}
#| label: tbl-completion
#| tbl-cap: "Capital project completion criteria"
#| tbl-pos: H

tibble(
  "Condition" = c("Stage 1 date <= Data export date", "Stage 1 date > Data export date"),
  "Status" = c("Completed", "Ongoing")
) %>%
  kable("latex") %>%
  kable_styling(latex_options = c("striped"), 
                full_width = FALSE, 
                position = "center") %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  column_spec(2, bold = TRUE, color = "red") 
```

## Project labour hours analysis

In the context of this analysis, labour hours refer to the total number of hours spent by both Melbourne Water personnel and the service provider’s personnel on each project. Examining labour hours across various delivery programs may provide insights into current crew resource management.

The data for this analysis is sourced partly from Melbourne Water’s internal enterprise resource planning (ERP) platform and partly from the service provider’s quarterly data submissions. A single data frame is then created by performing an inner join based on the project ID number.

\begin{noteBox}

Due to the sensitive nature of the data related to service provider submissions, a reproducible version of the dataset is not included in this analysis. However, visualisations and results will be detailed in later sections.

\end{noteBox}

## Classifying projects based on approval authority

Each capital project which is to be delivered within a CDM will require appropriate approvals from the relevant authority. The exact level of authorisation is generally based on the contract value of the project as well as the risk associated with each project. For the purpose of the current analysis, this decision is instead based on the FFC of the project. As a result, the total percentage of projects attributed to each authority is a conservative estimate of the actual expected projects. The FFC valuations that govern the authorisation level for a project is delineated in @tbl-approval.

As the valuation of a project rises, it typically requires to go through multiple approval gates. This may extend the duration to obtain the BCA significantly, thereby causing delays in resource allocation, selection of the service provider for the project, and subsequent crew mobilisation. Through the analysis of the percentage of projects which fall under each approval authority, an informed decision can be made on the expected duration of approvals for a project. 

```{r}
#| label: tbl-approval
#| tbl-cap: "Approval authority classification of projects based on FFC"
#| tbl-pos: H

tibble(
  "FFC of project ($)" = c("0-2.5 mil", "2.5-5 mil","5-8 mil","8-40 mil","40-75 mil","75-125 mil","> 125 mil"),
  "Approval authority" = c("People leadership group", "Senior leadership group","Executive leadership group","Managing director","Finance, audit and compliance"," Melbourne Water board","Department of Treasury and Finance")
) %>%
  kable("latex") %>%
  kable_styling(latex_options = c("striped"), 
                full_width = FALSE, 
                position = "center") %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  column_spec(2, bold = TRUE, color = "red") %>%  
  row_spec(0, bold = TRUE) %>%  # Keep headers bold
  row_spec(1:7,font_size = 8)
```

## Forecasting number of projects in the future CDM

The current analysis attempts to forecast the number of projects that are expected in CDM-26. For this purpose, the project data corresponding to the delivery models C-16 and C-21 are utilised to forecast the numbers in the future delivery model. As explained in @sec-limit, due to data migration and data integrity issues for the projects in the C-11 delivery model, this is not utilised as part of the current analysis.

Additionally, the forecasts were calculated for the projects with FFC valuations of 5 mil $ or lower. As explained in @sec-prodist, these subset of projects tend to form the majority of the projects for any delivery model and also requires about as much labour hours as all other projects combined. Hence, a forecasted number of projects in each month and year of the new delivery program can allow for better crew resource management and will additionally aid in proactive procurement of raw materials rather than reactive procurement, allowing for more efficient delivery process.

The forecasts will be performed using both benchmark techniques as well as specialised techniques. These are listed in @tbl-forecast and delineated further in @sec-forecast.


```{r}
#| label: tbl-forecast
#| tbl-cap: "Forecast techniques utilised for current analysis"
#| tbl-pos: H

tibble(
  "Forecast method" = c("Mean", "Naïve","Seasonal Naïve","ETS","ARIMA")) %>%
  kable("latex") %>%
  kable_styling(latex_options = c("striped"), 
                full_width = FALSE, 
                position = "center") %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  row_spec(0, bold = TRUE) %>%  # Keep headers bold
  row_spec(1:5, font_size = 8)
```
## Selecting an appropriate ETS forecast model {#sec-etsmethod}

The selection of the ETS model would require us to study the timeseries data of the projects worth 5 mil $ or lower in detail and outline any important timeseries characteristics that might be beneficial to obtain the appropriate ETS model for forecasting the projects in the upcoming delivery model. To train and evaluate the forecast models, a test dataset spanning from May 2022 to May 2024 is utilized. Projects completed before May 2022 serve as the training dataset.

Analyzing the decomposed data enables us to select the most appropriate type of ETS model for forecasting the number of projects in the upcoming delivery period. An additive decomposition of a timeseries data is obtained based on @eq-decomp. 

$$ \boxed{y_t = S_t + T_t + R_t}$$ {#eq-decomp}

Where,

$y_t$ is the data of interest, $S_t$ is the seasonal component of the timeseries, $T_t$ is the trend component and $R_t$ is the remainder.

@fig-decomp illustrates the additive decomposition of the time series data into its trend, seasonal, and remainder components. The key characteristics of this time series are outlined below.

1. There appears to be a cyclic trend in the data which repeats itself in approximately 3 years as observed through the sinusoidal trend line. This indicates that there is no clear additive or multiplicative trend in the data which can be replicated through the ETS model. The ETS model is however well suited to work with cyclic data.

2. The seasonality of the current timeseries data indicates around 3 peaks when projects get approved in each year. Additionally, the seasonality appears to be fairly consistent throughout the years, indicating additive seasonality of the data.

3. The scale of the remainder appears to be large, meaning that the model is unable to capture some important characteristics in the timeseries, possibly due to the limited availability of the current data.

4. The remainder appears to have no distinct patterns in it and is centered around zero. This is an ideal outcome as it shows that information left over after accounting for the trend and seasonality in the data is unbiased and has a mean of zero over the entire timeseries. 

5. Additionally, it can be observed through the autocorrelation function (ACF) plot in @fig-resid that the residuals are uncorrelated in nature, meaning no discernible patterns have leaked into the residuals.

6. The distribution of the residuals has a __right skew__. While this may not affect the point forecasts directly, however, this is expected to __affect the prediction intervals which are assumed to be normally distributed in nature.__


```{r}
#| label: fig-decomp
#| fig-cap: "Time series decomposition for projects with FFC valuation of 5 mil $ or lower"
#| fig-height: 4 
#| fig-width: 8

components(dcmp) %>% autoplot() + 
  labs(title = "Time series decomposition plot",
       subtitle = "Projects with FFC <= 5 mil $",
       x = "Timeline",
       y = "Number of projects") + theme_minimal()
```

```{r}
#| label: fig-resid
#| fig-cap: "Residual diagnostic plots"
#| fig-height: 4 
#| fig-width: 8
gg_tsresiduals(dcmp) + labs(x = "Timeline",
                            title = "Residual diagnostics for timeseries data",
                            subtitle = "Projects with FFC <= 5 mil $") 
```
\begin{warningBox}
The current forecast models face limitations due to the unavailability of project data beyond the current and past CDM. As a result, the forecasts exhibit high uncertainty, characterized by large residuals and broad prediction intervals.

Nevertheless, with the accumulation of additional data in the future, the model is anticipated to produce more accurate point forecasts and narrower, more informative prediction intervals. The primary objective of this study is to establish a reproducible pipeline for generating these forecasts.
\end{warningBox}


## Tracking service provider's performance through KPIs and KRAs

The critical phase of a project initiates from the BCA to stage 3. As this is the period when the resources get allocated to projects, each day is expected to cost Melbourne Water. Hence, it is paramount to keep a track on the project completion and at the same time, ensure that the delivery of the project meets the quality requirements.

@kunkcu2022using have studied various construction management projects utilizing key performance indicators (KPIs) and found them to be highly effective tools for evaluating project performance. In the context of Melbourne Water's projects, the focus is to engage a service provider who is able to deliver the project within the constrained time period, communicates progress regularly, minimises cost and time variations,reports and mitigates unsafe work conditions, engages a diverse group of employees, and undertakes sustainable initiatives. These are called the key result areas (KRAs) and are drawn into a legal agreement while employing a service provider. A high KRA score often attracts a monetary incentive for the service provider, thereby making this an area of interest for both the key parties.

While the KRAs are subjective in nature and difficult to track, each of them are further quantified through the usage of KPIs. Based on the data provided by the service providers and through careful feature engineering, a framework to track and analyse project progress is delineated in @sec-results. The role of the KPIs and KRAs are two-fold. First, these indicators allow the team at Melbourne Water to gauge the progress of the project, secondly, it allows Melbourne Water to engineer the right behaviour on the part of the service provider who is responsible for the construction of the project. @fig-flowchartkpi illustrates the scope of the KRAs and KPIs within a project.

![KRA-KPI flowchart](images/kra_kpi.png){#fig-flowchartkpi}



# Results and Discussion {#sec-results}

## Distribution of delivery programs within each CDM

Each CDM contains specific delivery programs under which a project is managed right from the concept stage to the delivery stage. Such a process is undertaken to make the project delivery process more efficient and allow for better efficiency in allocating resources. Delivery programs differ from one another based on factors such as risk associated with the project, cost of the project and the tendering process to complete the project.

@fig-comp illustrates the compositions of the current delivery model (CDM-21) and the past model (CDM-16). Some of the observations are delineated below:

1. In each of the CDMs, the Open Market projects constitute the smallest proportion. This is usually the case because such projects tend to incur a large sum of FFC and some of these projects could also be "green-field" projects that take a long time period for delivery.

2. While the percentage of "Framework" projects reduced from CDM-16 to CDM-21, a subsequent rise in "Small-scale" and "Contestable" projects were observed within the same period. It is especially interesting to note that the current model delivers nearly half of all the projects through the "Small-Scale" program.

3. Allocating more projects through the delivery programs of "Small-scale" and "Contestable" route in the current model was expected to expedite the delivery period of projects as these programs typically require fewer approvals and consequently, lesser time to reach the BCA stage.

4. In the future CDM, a similar strategy may be utilised to expedite projects by requiring fewer approval gates and delivering projects quicker.

```{r}
#| label: fig-comp
#| fig-cap: "Composition of the delivery programs within each CDM"
#| fig-height: 3 
#| fig-width: 8
project_group_progam <- project_data %>%
  group_by(delivery_program, cdm) %>%
  summarise(Total = n()) %>%
  ungroup() %>%
  group_by(cdm) %>%
  mutate(Percentage = Total / sum(Total))

cc <- c("Contestable" = "#FF6F61" , 
        "Major Works - Framework" = "#40E0D0" ,
        "Major Works - Open Market" = "#FFD700",
        "Major Works - Small Scale" = "#87CEFA")

ggplot(project_group_progam %>% filter(cdm != "CDM-26"),aes(x = Percentage,
                                y = cdm,
                                fill = delivery_program)) + geom_col() +
  geom_text(aes(label = scales::percent(Percentage, accuracy = 1)), 
            position = position_fill(vjust = 0.5), size = 3) +
  scale_x_continuous(expand = c(0, 0), labels = scales::percent) +
  labs(title = "Distribution of delivery programs within each CDM",
       y = "Capital Delivery Model",
       caption = "Source: Melbourne Water Corporation",
       fill = "Delivery program") +
  scale_fill_manual(values = cc) + theme_minimal()
```
## Distribution of projects by FFC bands for each delivery model {#sec-prodist}

@fig-ffcband illustrates the distribution of the project FFCs associated with each CDM. Key observations are delineated below:

1. In each of the CDMs, projects that are worth 5 mil $ or lower tend to constitute more than 2/3rd of all the approved projects.

2. On the other hand, projects which are worth 50 mil $ or higher remain to be the smallest category of projects in each of the CDMs.

3. Analysis of the current and the previous CDMs suggest that the new delivery model (CDM-26) would be expected to constitute majority of the projects with FFCs below 5 mil $.

4. Such projects are associated with works such as laying new pipelines, pipeline renewals, mechanical or electrical machinery maintainence and other works of similar nature. As a result, the demand for these projects in each year are expected to remain fairly consistent, and hence provides valuable insights what the new delivery model could shape up as.  


```{r}
#| label: fig-ffcband
#| fig-cap: "Project FFC band distribution across different CDMs"
#| fig-height: 3 
#| fig-width: 8
#| fig-pos: H

project_group_progam <- project_data %>%
  group_by(ffc_band, cdm) %>%
  summarise(Total = n()) %>%
  ungroup() %>%
  group_by(cdm) %>%
  mutate(Percentage = Total / sum(Total))

dim_order <- c("> 80","50-80","20-50","10-20","5-10","< = 5")

project_group_progam$ffc_band <- factor(project_group_progam$ffc_band, levels = dim_order)

ggplot(project_group_progam %>% filter(cdm != "CDM-26"),aes(x = Percentage,
                                y = cdm,
                                fill = ffc_band)) + geom_col(position = "fill") +
  labs(x = "Percentage of projects by number",y = "Capital Delivery Model",
       title = "Distribution of project forecast costs across Capital Delivery Models",
       caption = "Source: Melbourne Water Corporation",
       fill = "Cost bands (in mil $)") +
  geom_label_repel(aes(label = scales::percent(Percentage, accuracy = 1)), 
            position = position_fill(vjust = 0.5), size = 3,color = "white",fontface = "bold") +
  scale_x_continuous(expand = c(0, 0), labels = scales::percent) +
  scale_fill_tableau(palette = "Miller Stone") + theme_minimal() 


```




```{r}
#| label: fig-ffcprop
#| fig-cap: "Cumulative project valuations across different CDMs and FFC bands"
#| fig-height: 4 
#| fig-width: 8

project_group_progam <- project_data %>%
  group_by(ffc_band, cdm) %>%
  summarise(Total = sum(ffc)) %>%
  ungroup() %>%
  group_by(cdm) %>%
  mutate(Percentage = Total / sum(Total))

dim_order <- c("> 80","50-80","20-50","10-20","5-10","< = 5")

project_group_progam$ffc_band <- factor(project_group_progam$ffc_band, levels = dim_order)

ggplot(project_group_progam %>% filter(cdm != "CDM-26"),aes(x = Percentage,
                                y = cdm,
                                fill = ffc_band)) + geom_col(position = "fill") +
  labs(x = "Percentage of projects by total valuation",y = "Capital Delivery Model",
       title = "Distribution of total valuation of projects across delivery models and cost bands",
       caption = "Source: Melbourne Water Corporation",
       fill = "Cost bands (in mil $)") +
  geom_label_repel(aes(label = scales::percent(Percentage, accuracy = 1)), 
            position = position_fill(vjust = 0.5), size = 3,color = "white",fontface = "bold") +
  scale_x_continuous(expand = c(0, 0), labels = scales::percent) +
  scale_fill_tableau(palette = "Miller Stone") + theme_minimal() 


```

## Estimating number of projects to be approved by each approval body

Analysing the breakdown of the projects for the past and the current CDM could provide critical information on what would the future CDM distribution look like. This is especially true as there is a clear dependence on the duration of project approval depending upon the approval authority as illustrated by @fig-approvaltime. @tbl-approval shows the criteria of approval body allocation for a project based on the risk and the FFC valuation of these projects.

Some of the key observations and recommendations based on the breakdown of the projects by approval body for CDM-16 and CDM-21 as illustrated by @fig-approval are as follows:

1. More than half of the projects within a CDM are expected to be approved by the "People Leadership Group". Based on the past approval durations, these projects are those with smaller FFC valuations and may expect quicker approval. In the future delivery model, this trend is expected to continue. For projects which may exceed the approval limit and eventually take longer time to get approved, they can be further broken down into smaller projects of lower FFC valuations and bundled together to benefit from the quicker approval periods.

2. The percentage of projects approved by the “Senior Leadership Group,” “Finance, Audit, and Compliance,” and “Managing Director (MD)” has remained consistent over the past two CDMs, suggesting a stable pattern in the composition of future approvals. Analyzing the approval durations, as shown in @fig-approvaltime, offers a benchmark for the time required in the approval process. This information can be used to plan effectively and address potential risks associated with approval delays in advance.

3. With an anticipated increase in the number of projects for the upcoming delivery program, which will require approval from the DTF, it is important to address potential delays. Historically, these projects face prolonged approval times due to associated costs, risks, and the need for coordination with external government agencies. To streamline the approval process, it is advisable to negotiate special considerations or exemptions with the ministry and DTF. This approach could help mitigate barriers and facilitate a more timely approval for these complex, large-scale, high-risk projects.

```{r}
#| eval: false

project_approval_duration <- project_data %>% filter(cdm != "CDM-26") %>% 
  group_by(approval_body) %>% mutate(approval_duration = days(bca-pbc)) 

project_approval_duration <- project_approval_duration %>% mutate(approval_body_dummy = case_when( approval_body ==  "DTF" ~ "Government approval",
                                                                   approval_body == "MW Board" ~ "Board of directors",
                                                                   approval_body == "Finance, Audit and Compliance" ~ "Finance and Audit",
                                                                   approval_body == "MD" ~ "Managing Director",
                                                                   approval_body ==  "Executive Leadership Group" ~ "Level 1 authority",
                                                                   approval_body == "Senior Leadership Group" ~ "Level 2 authority",
                                                                   approval_body == "People Leadership Group" ~ "Level 3 authority"))


dim_order <- c("Level 3 authority","Level 2 authority","Level 1 authority","Managing Director","Finance and Audit",
               "Board of directors","Government approval")

project_approval_duration$approval_body_dummy <- factor(project_approval_duration$approval_body_dummy,levels =  dim_order )

options(scipen = 1000)



project_approval_duration %>%
  ggplot(aes(y = approval_body_dummy,x = day(approval_duration))) + geom_boxplot() +
  labs(x = "Approval duration (Days)",
       y = "Approval body",
       title = "Project approval duration for various authorities",
       caption = "Source: Melbourne Water Corporation") +
 facet_wrap(~cdm) + theme_minimal()
```

```{r}
#| label: fig-approvaltime
#| fig-cap: "Distribution of project approval duration for various approval bodies "
#| fig-height: 4 
#| fig-width: 8
app_order <- c("People Leadership Group","Senior Leadership Group","Executive Leadership Group",
               "MD","Finance, Audit and Compliance","MW Board","DTF")

options(scipen = 1000)
project_approval_duration <- project_data %>% filter(cdm != "CDM-26") %>% 
  group_by(approval_body) %>% mutate(approval_duration = days(bca-pbc)) 

project_approval_duration$approval_body <- factor(project_approval_duration$approval_body, levels = app_order)

project_approval_duration %>%
  ggplot(aes(y = approval_body,x = day(approval_duration))) + geom_boxplot() +
  labs(x = "Approval duration (Days)",
       y = "Approval body",
       title = "Project approval duration for various authorities",
       caption = "Source: Melbourne Water Corporation") +
 facet_wrap(~cdm) + theme_minimal()
```
```{r}
#| eval: false
project_group_approval <- project_group_approval %>% mutate(approval_body_dummy = case_when( approval_body ==  "DTF" ~ "Government approval",
                                                                   approval_body == "MW Board" ~ "Board of directors",
                                                                   approval_body == "Finance, Audit and Compliance" ~ "Finance and Audit",
                                                                   approval_body == "MD" ~ "Managing Director",
                                                                   approval_body ==  "Executive Leadership Group" ~ "Level 1 authority",
                                                                   approval_body == "Senior Leadership Group" ~ "Level 2 authority",
                                                                   approval_body == "People Leadership Group" ~ "Level 3 authority"))


dim_order <- c("Government approval","Board of directors","Finance and Audit",
               "Managing Director","Level 1 authority","Level 2 authority","Level 3 authority")

project_group_approval$approval_body_dummy <- factor(project_group_approval$approval_body_dummy, levels = dim_order)

ggplot(project_group_approval %>% filter(cdm != "CDM-26"),aes(x = Percentage,
                                y = cdm,
                                fill = approval_body_dummy)) + geom_col(position = "fill") +
  labs(x = "Percentage of projects",y = "Capital Delivery Model",
       title = "Distribution of projects based on approval body across delivery models",
       caption = "Source: Melbourne Water Corporation",
       fill = "Approval body") +
  geom_label_repel(aes(label = scales::percent(Percentage, accuracy = 1)), 
            position = position_fill(vjust = 0.5), size = 3,color = "white",fontface = "bold") +
  scale_x_continuous(expand = c(0, 0), labels = scales::percent) +
  scale_fill_tableau(palette = "Tableau 10") + theme_minimal() 
```


```{r}
#| label: fig-approval
#| fig-cap: "Distribution of projects across various approval bodies and CDMs"
#| fig-height: 4 
#| fig-width: 8

project_group_approval <- project_data %>%
  group_by(approval_body, cdm) %>%
  summarise(Total = n()) %>%
  ungroup() %>%
  group_by(cdm) %>%
  mutate(Percentage = Total / sum(Total))


ggplot(project_group_approval %>% filter(cdm != "CDM-26"),aes(x = Percentage,
                                y = cdm,
                                fill = approval_body)) + geom_col(position = "fill") +
  labs(x = "Percentage of projects",y = "Capital Delivery Model",
       title = "Distribution of projects based on approval body across CDMs",
       caption = "Source: Melbourne Water Corporation",
       fill = "Approval body") +
  geom_label_repel(aes(label = scales::percent(Percentage, accuracy = 1)), 
            position = position_fill(vjust = 0.5), size = 3,color = "white",fontface = "bold") +
  scale_x_continuous(expand = c(0, 0), labels = scales::percent) +
  scale_fill_tableau(palette = "Tableau 10") + theme_minimal() 
```


## Labour utilisation analysis for each delivery program

@fig-labour depicts the distribution of the labour hours across each of the four delivery programs within MCD. The plot indicates that the current model is capable of delivering multiple small-scale and low risk contestable projects. The labour hours associated with Major Works-Framework and Major Works-Small Scale appear to be fairly similar, despite the fact that the __Small Scale projects account for about only 10% of the FFC in a delivery period__. The future CDM for PS-26 should consider __streamlining or bundling multiple small-scale projects together to generate higher efficiency in Project Management labour resource allocation.__ 

![Distribution of labour hours of each delivery program](images/labour_hours.png){#fig-labour}

## Critical project stage duration analysis 

As explained previously through @fig-flowchart, a project typically undergoes several key critical stages from conceptualisation to completion. It is critical to study the duration in between these stages and also compare across CDMs to observe any changes and what it may mean for the future CDM.

@fig-compduration compares the duration of time taken to submit a business case for further approval once a project has been conceptualised. This is quantified by calculating the duration between the BNI stage and the PBC stage of the project lifecycle. The comparison was done only for the delivery programs under Major Works-Framework and Major Works-Open Market as the other programs are generally fast-tracked by bypassing the PBC stage. Some of the key observations are as follows:

1. In each of the CDMs, the duration of time for project conceptualisation is higher for Major Works-Open Market as compared to Major Works-Framework. This is typically the case due to the fact that a business case for Frameworks projects are contracted to a list of already approved service providers and will be engaged through a specific working contract which was agreed between the parties previously. On the other hand, Open Market projects are those that need to be tendered in the market and may require to form a working partnership with a new service provider. This leads to the requirement of further due-diligence, risk and cost analysis, contractual deliverables review and liaising with other government bodies to finalise a business case. As a result, the median duration for project concept submission is typically longer for these projects.

2. The median time taken between the BNI and PBC stages, referred to as the project conceptualization stage, has increased from CDM-16 to CDM-21. In CDM-21, the median duration for each delivery program exceeded 2 years, which is significantly longer than the durations observed in CDM-16. For future CDMs, it is advisable to consider these extended durations and explore strategies to reduce the time required for projects to progress from BNI to PBC, aiming to align with the shorter durations seen in CDM-16.

3. Several outliers were observed in the business case submission duration for Major Works-Framework projects under CDM-16. These outliers were significantly higher than the median durations for both Framework projects and Open Market projects. Investigating the causes of these delays can provide valuable insights. Understanding these issues is expected to benefit the upcoming CDM by helping to streamline the business case submission process and minimize any inadvertent delays.

```{r}
#| label: fig-compduration
#| fig-cap: "Comparison of PBC duration across CDMs"
#| fig-height: 4 
#| fig-width: 8

project_data <- project_data %>% mutate(conception_duration = days(pbc - bni))

del_prg <- c("Major Works - Framework","Major Works - Open Market")

ggplot(data = project_data %>% filter(delivery_program %in% del_prg  & cdm != "CDM-26"),aes(y = day(conception_duration),x = delivery_program,fill = delivery_program)) + geom_boxplot()  + facet_wrap(~cdm) +
  theme_minimal() + theme(legend.position = "none",axis.text.x = element_text(size = 8)) + 
  labs(x = "Delivery program",
       y = "Duration (Days)",
       caption = "Source: Melbourne Water Corporation", 
       title = "Distribution of duration for preliminary business case submission",
       subtitle = "Number of days between BNI and PBC") + scale_fill_tableau(palette = "Superfishel Stone")
```
The other critical stage of the projects is to monitor the duration between the project approval (BCA) to project delivery (Stage 1). @fig-delduration illustrates how the duration of projects from approval to delivery stage differ across various delivery programs. Key insights from this visualisation are as follows:

1. The current sample of all completed projects indicate a right skewed distribution. This suggests that there are some projects which require unusually longer to complete across all delivery programs, possibly due to project cost variations, scope changes or other hurdles.

2. The number of "Open Market" and "Contestable" projects are typically very low in number within any CDM. As a result, its distribution of completion duration is not expected to provide a representative figure for the future delivery model due to the resultant spread of the data.

3. On the other hand, both the "Small scale" and "Framework" projects together constitute more than 2/3rd of the total proportion of projects. As a result, the distribution of the project completion duration may provide a good prior information for the upcoming delivery model under vastly similar circumstances.

4. The distribution of completion durations for “Framework” and “Small-scale” projects indicates that the majority of these projects are completed in __approximately one year.__ This insight is crucial for estimating the expected duration for a significant portion of projects in the upcoming CDM. It can help optimise resource and crew allocation, ensuring more efficient project management and planning.

5. The completion duration for projects under "Contestable" and "Open-Market" projects are comparable to one another and spans for __nearly a year and three months.__ 

```{r}
project_data <- project_data %>% mutate(completion_duration = days(stage1 - bca)) %>% mutate(delivery_program_dummy = case_when(delivery_program == "Major Works - Small Scale" ~ "Small scale projects",
                                                                        delivery_program == "Major Works - Framework" ~ "Framework projects",
                                                                        delivery_program == "Major Works - Open Market" ~ "Large scale projects",
                                                                        delivery_program == "Contestable" ~ "Small scale contestable projects"))

delduration <- ggplot(data = project_data %>% filter(status == "Completed"),aes(x = day(completion_duration),fill = delivery_program_dummy)) + geom_density()  + scale_fill_tableau(palette = "Tableau 10") + theme_minimal() + 
facet_wrap(~delivery_program_dummy,ncol = 1) + theme(legend.position = "none",
                                               plot.title = element_text(size = 10),
                                               plot.subtitle = element_text(size = 8),
                                               axis.text = element_text(size = 7)) +
  labs(x = "Project completion duration (days)",
y = "Density",
caption = "Source: Melbourne Water Corporation",
title = "Distribution of project duration after completion",
subtitle = "Number of days between BCA and Stage 1")

```

```{r}
#| eval: false
medduration <- project_data %>% filter(status == "Completed") %>% 
  group_by(delivery_program) %>%
  summarise(Median_completion = median(day(completion_duration))) 

medduration <- medduration %>% mutate(delivery_program_dummy = case_when(delivery_program == "Major Works - Small Scale" ~ "Small scale projects",
                                                                        delivery_program == "Major Works - Framework" ~ "Framework projects",
                                                                        delivery_program == "Major Works - Open Market" ~ "Large scale projects",
                                                                        delivery_program == "Contestable" ~ "Small scale contestable projects"))

medduration <- medduration %>% 
  ggplot(aes(y = reorder(delivery_program_dummy,-Median_completion), x = Median_completion, fill = delivery_program_dummy)) + 
  geom_col() + scale_fill_tableau(palette = "Tableau 10") + 
  geom_label(aes(label = round(Median_completion,0),hjust = 1)) +  theme_minimal() + theme(legend.position = "none",
                                                                        plot.title = element_text(size = 10),
                                                                        plot.subtitle = element_text(size = 8),
                                                                        axis.text = element_text(size = 7)) + 
  labs(x = "Duration (Days)",
       y = "Delivery program",
       title = "Median duration for project completion",
       subtitle = "Number of days between BCA and Stage 1",
       caption = "Source: Melbourne Water Corporation")

```


```{r}

medduration <- project_data %>% filter(status == "Completed") %>% 
  group_by(delivery_program) %>%
  summarise(Median_completion = median(day(completion_duration))) 


medduration <- medduration %>% 
  ggplot(aes(y = reorder(delivery_program,-Median_completion), x = Median_completion, fill = delivery_program)) + 
  geom_col() + scale_fill_tableau(palette = "Tableau 10") + 
  geom_label(aes(label = round(Median_completion,0),hjust = 1)) +  theme_minimal() + theme(legend.position = "none",
                                                                        plot.title = element_text(size = 10),
                                                                        plot.subtitle = element_text(size = 8),
                                                                        axis.text = element_text(size = 7)) + 
  labs(x = "Duration (Days)",
       y = "Delivery program",
       title = "Median duration for project completion",
       subtitle = "Number of days between BCA and Stage 1",
       caption = "Source: Melbourne Water Corporation")

```

```{r}
#| label: fig-delduration
#| fig-cap: "Distribution of project completion duration across delivery programs"
#| fig-height: 5 
#| fig-width: 8
(delduration + medduration) +
  plot_layout(nrow=1, heights = c(5,5)) &
  plot_annotation(
    theme = theme(plot.background = element_rect(color = "white", linewidth = 2, fill = "white"),
                  strip.background = element_rect(color = "white")) + theme_minimal()
  )
```



## Forecasting number of projects in CDM-26 {#sec-forecast}

@tbl-forecast lists out the forecasting models which will be implemented to obtain the forecasts of the projects worth 5 mil $ or lower. These include benchmark models such as the "Mean" and the "Seasonal Naïve" alongwith the specialised forecast method called the ETS method. For the purpose of training the forecast models, project data between 2016 January to 2022 May is used as the training dataset while the test dataset includes the project data between 2022 June to 2024 May. 

@fig-forecompvizbm illustrates the performance of the benchmark forecast models on the test dataset. The visualisation further overlays the actual approved projects in the test dataset duration between 2022 June to 2024 May. Some of the key observations are as follows:


1. The Seasonal Naïve model, which forecasts future expected projects by replicating the annual seasonality and trend from the current year, demonstrated greater confidence compared to the standard Naïve model, as evidenced by its narrower prediction intervals. However, this model assumes that the seasonal patterns and trends observed in the current period will persist unchanged into future years. This assumption may be overly stringent, particularly for capital delivery models that are influenced by business cycles. Additionally, the seasonal patterns in the training data may not be strong enough to support this assumption reliably.

2. The Mean model, which forecasts future projects based on the average number of projects observed in the training data, exhibits the highest level of confidence among the benchmark models, as indicated by its narrow prediction intervals. This model assumes that small-scale projects valued at $5 million or less will remain relatively consistent each year due to their regular demand, making forecasting based on the historical mean a reasonable assumption. However, this model’s simplicity comes with limitations, as it does not account for seasonality or trends in the data, potentially making it less informative about the underlying patterns.

3. The current models encounter a significant challenge when forecasting small discrete values, such as the number of expected monthly projects. As noted by @hyndman2018forecasting, these statistical models produce continuous value forecasts and can contain negative lower prediction intervals when the mean is close to 0. Such an outcome that is not meaningful for expected number of projects as forecasts. In this analysis, a specialised implementation of the ETS model, known as Croston’s method, is attempted and compared against other benchmark and ETS models. While Croston’s method is better suited for handling data with zeros or small counts, it has a key limitation as per @shenstone2005stochastic : it does not correspond to a formal statistical model, and thus, prediction intervals cannot be computed.


\begin{noteBox}
It is important to note that the lower prediction intervals for the Season Naïve models cover the negative Y-axis. This is however not possible in real practice when forecasting number of projects. In order to prevent this issue, all lower prediction intervals are truncated to values greater than or equal to 0.

\end{noteBox}

```{r}
#| message: false
#| warning: false
project_tsibble_train <- project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` <= ymd(20220501))
project_tsibble_test <- project_tsibble %>% filter(ffc_band == "< = 5" & 
                                                     `yearmonth(bca)` > ymd(20220501) & 
                                                     `yearmonth(bca)` < ymd(20240601))

model_fit <- project_tsibble_train |> 
  model(
     Mean = MEAN(Total),
    Naive = NAIVE(Total),
    Season_Naive = SNAIVE(Total),
    ETS_ana = ETS(Total ~ error("A") + season("A")),
    Croston = CROSTON(Total))


```





```{r}
#| label: fig-forecompvizbm
#| fig-cap: "Forecasts of benchmark models overlayed on the approved projects"
#| fig-height: 4
#| fig-width: 8
model_fit %>% select(-c(ETS_ana,Naive,Croston)) %>% forecast(h = "2 years",bootstrap =TRUE) %>% mutate(Total = distributional::dist_truncated(Total, 0)) %>%
 autoplot() + geom_line(
    data = project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)),
    aes(x = `yearmonth(bca)`, y = Total, linetype = "Approved projects")) + guides(
    color = guide_legend(title = "Forecast model"),
    fill = guide_legend(title = "Forecast model"),
    linetype = guide_legend("Actual data")) + 
  labs(title = "Benchmark forecast model performance in test dataset",
       subtitle = "Projects with FFC <= 5 mil $",
       y = "Total number of projects",
       x = "Timeline",caption = "Source: Melbourne Water Corporation") + theme_minimal()
```

@sec-etsmethod delineated the process of selecting the ETS method which will be used for forecasting the number of projects. Based on the decomposition of the timeseries data, the type of ETS model which will be used for forecasting is the __ETS (A,N,A) model.__ @fig-forecompvizets illustrates the performance of the model on the test dataset. Some of the key observations are as follows:

1. The ETS (A,N,A) model forecasts the number of projects with an additive seasonality. Since the trend of the data appeared to be cyclic in nature when performing its decomposition, hence, it was considered to be stationary and as a result, no trend was modelled in the forecasts.

2. Current forecast model is limited by the relatively short duration of projects in the training dataset. As a result, the prediction intervals are moderately wide. While forecasting for future delivery models, as the size of the training dataset enlarges, the forecast models would be expected to be more confident and have narrower prediction intervals.

3. Within the initial period of the test dataset (in 2022), the point forecasts were higher than the actual approved projects. However, towards the later part of the dataset, specifically in the years of 2023 and 2024, the point forecasts were closer to the actual number of projects.

4. The actual approved projects consistently fell within the 80% and 95% prediction intervals for nearly the entire duration of the test dataset. This suggests that the current ETS model has effectively captured the underlying pattern in the data.

```{r}
#| label: fig-forecompvizets
#| fig-cap: "Forecasts of ETS model overlayed on the approved projects"
#| fig-height: 4
#| fig-width: 8
model_fit %>% select(ETS_ana) %>% forecast(h = "2 years",bootstrap =TRUE) %>%  mutate(Total = distributional::dist_truncated(Total, 0)) %>% 
 autoplot() +  geom_line(
    data = project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)),
    aes(x = `yearmonth(bca)`, y = Total, linetype = "Approved projects")) + guides(
    color = guide_legend(title = "Forecast model"),
    fill = guide_legend(title = "Forecast model"),
    linetype = guide_legend("Melbourne Water data")) + 
  labs(title = "ETS (A,N,A) forecast model performance on test dataset",
       subtitle = "Projects with FFC <= 5 mil $",
       y = "Total number of projects",
       x = "Timeline",caption = "Source: Melbourne Water Corporation") + 
  theme(legend.text = element_text(size = 7),
        legend.title = element_text(size = 9)) +
  theme_minimal()
```

```{r}
#| eval: false
model_fit %>% select(ETS_ana,arima_auto) %>% forecast(h = "2 years",bootstrap =TRUE) %>%  mutate(Total = distributional::dist_truncated(Total, 0)) %>%
 autoplot() + geom_line(
    data = project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)),
    aes(x = `yearmonth(bca)`, y = Total, linetype = "Approved projects")) + guides(
    color = guide_legend(title = "Forecast model"),
    fill = guide_legend(title = "Forecast model"),
    linetype = guide_legend("Actual data")) + 
  labs(title = "Specialised forecast model performance comparison with actual data",
       subtitle = "Projects with FFC <= 5 mil $",
       y = "Total number of projects",
       x = "Timeline",caption = "Source: Melbourne Water Corporation") + 
  theme(legend.text = element_text(size = 7),
        legend.title = element_text(size = 9)) +
  theme_minimal()
```

In order to compare the various forecast models, we will utilise the root mean squared error (RMSE) on the out-of-sample test dataset. The RMSE is calculated through @eq-rmse. The RMSE is additionally a useful metric to compare forecast models as the results are in the same scale as the forecasts and hence, can be easily interpreted as the average magnitude of errors between the predicted and actual values.

$$RMSE = {\sqrt{\sum_{i=1} ^{N}\dfrac{(\hat{y_i} - y_i)^2}{N}}}$$ {#eq-rmse}

@tbl-rmse shows the performance of the forecast models on the current out-of-sample test dataset. Although the Mean model had the lowest error, however due to the limitations of this model mentioned previously, we would expect the ETS (A,N,A) model to perform better with a larger training dataset in the future. As a result, the current forecasts for the projects in CDM-26 will be based off the ETS (A,N,A) model. These forecasts are depicted through @fig-forecastcdm26.

```{r}
#| label: tbl-rmse
#| tbl-cap: "RMSE of various forecast models"
#| tbl-pos: H
model_fit  |> forecast(h = 24) |> accuracy(project_tsibble %>%
                                             filter(ffc_band == "< = 5" &
                                                      `yearmonth(bca)` < ymd(20240601))) |>
  filter(.type == "Test") %>%
  select(-ME, -MPE, -ACF1,-MAPE, -ffc_band,-.type) %>% arrange(RMSE) %>% kable("latex",digits = 2) %>%
  kable_styling(latex_options = c("striped"), 
                full_width = FALSE, 
                position = "center") %>%
  column_spec(1, bold = TRUE, color = "blue") %>%
  column_spec(2, bold = TRUE, color = "red") 
```


```{r}
model_fit <- project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)) |> 
  model(
     Mean = MEAN(Total),
    Naive = NAIVE(Total),
    Season_Naive = SNAIVE(Total),
    ETS_auto = ETS(Total),
    ETS_ana = ETS(Total ~ error("A") + season("A")),
    arima_auto = ARIMA(Total))
```


```{r}
#| label: fig-forecastcdm26
#| fig-cap: "Forecasted number of projects in CDM-26 using ETS (A,N,A) model"
#| fig-height: 4
#| fig-width: 8
model_fc <- model_fit %>% select(ETS_ana) |> forecast(h = 72,bootstrap =TRUE) %>%  mutate(Total = distributional::dist_truncated(Total, 0)) 

model_fc |> autoplot() +
   geom_line(
    data = project_tsibble %>% filter(ffc_band == "< = 5" & `yearmonth(bca)` < ymd(20240601)),
    aes(x = `yearmonth(bca)`, y = Total, linetype = "Approved projects")
  ) + 
  guides(
    color = guide_legend(title = "Forecast model"),
    fill = guide_legend(title = "Forecast model"),
    linetype = guide_legend("Actual data")
  ) +
  labs(
    x = "Timeline",
    y = "Number of projects",
    title = "Forecasted number of projects in CDM-26 using specialised forecast models",
    subtitle = "Projects worth 5 mil $ or lower",
    caption = "Source: Melbourne Water Corporation"
  ) + theme_minimal()


```


# Conclusion

The current CDM data analysis and forecasting project yielded the following results :

1. Based on the analysis of sample data from CDM-21 and CDM-16, the new delivery model is projected to successfully deliver __at least 70% of the projects with a forecasted final cost (FFC) of $5 million or less.__

2. Projects with higher valuations and associated risks require approval from higher authorities, often external to the department or organization. This can lead to significantly longer approval times, with some projects taking well over a year to reach the “approved” stage. The current study recommends segmenting high-valuation projects into smaller, “bundled” projects to expedite the approval process, __potentially reducing the approval duration to approximately 8 months (250 days) and follow an approval process which is within the department or the organisation.__

3. In the upcoming delivery model, it is expected that __more than half of all the projects will need to be approved by the "People leadership group".__ Additionally, the percentage of projects approved by the “Senior Leadership Group,” “Finance, Audit, and Compliance,” and “Managing Director (MD)” has remained __consistent over the past two CDMs,suggesting a stable pattern in the composition of future approvals.__

4. Although __Small-Scale delivery program projects account for approximately 10 % of the total valuation of projects__ within a CDM, the labour utilisation is however the same as that of Frameworks delivery program projects which delivers a significantly larger proportion of the total valuation. The future Capital Delivery Model for PS-26 should explore __streamlining or bundling multiple Small-Scale projects to enhance efficiency in project management and optimize labor resource allocation.__






# Key areas of improvement

The current data analysis and forecasting project was created with the goal of formalising a reproducible framework to obtain valuable insights from past delivery models that could be utilised for designing the next delivery model. While the study delineated various factors which can be taken into account, there are several improvements to the current analysis that can make the insights further robust and accessible. These are listed as follows:

1. __Incorporating Spatial Analysis:__ The current study primarily focuses on temporal analysis, and spatial analysis has not been implemented due to data constraints. However, incorporating spatial analysis is expected to uncover valuable patterns and insights, especially regarding resource allocation and demand based on the location of the asset. Future analyses should integrate geographical data to provide a deeper understanding of projects across various asset locations of the organization.

2. __Incorporating Inflation Factors in forecasts:__ While current forecasting methods are capable of predicting the total valuation of projects, they do not account for inflationary factors such as increases in raw material and manpower costs. Future developments in forecasting methods should incorporate the Consumer Price Index (CPI) to better estimate the total expected valuation of projects, reflecting the impact of inflation on project costs. Such forecasts would allow the project teams to get an informed idea regarding the various cost allocations.

3. __Visualisation and Accessibility:__ To make the current study available to a broader audience, the insights and visualisations can be replicated on a PowerBI organisational dashboard. This would have the added benefit of leveraging Microsoft Fabric’s datalake where the live data can be extracted, transformed and loaded onto the dashboard, providing insights based on live project data.

4. __Implementing KRA and KPI dashboard reporting:__ Incorporating Key Result Areas (KRAs) and Key Performance Indicators (KPIs) into the dashboard facilitates effective tracking of current projects against historical data and organizational benchmarks. These indicators enable organisations to assess project delivery performance and efficiency across different service providers and project types. By developing these metrics in close consultation with business leaders, they can be tailored to align with strategic objectives and then visualized for quick and intuitive access on the dashboard.

# Packages used

1. __Tidyverse__: Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM,
  Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). “Welcome to the tidyverse.” _Journal of
  Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.
2. __fpp3__: Hyndman R (2023). _fpp3: Data for "Forecasting: Principles and Practice" (3rd Edition)_. R package version 0.5, <https://CRAN.R-project.org/package=fpp3>.

3. __ggthemes__: Arnold J (2024). _ggthemes: Extra Themes, Scales and Geoms for 'ggplot2'_. R package version 5.1.0, <https://CRAN.R-project.org/package=ggthemes>.

4. __janitor__: Firke S (2023). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.0, <https://CRAN.R-project.org/package=janitor>.

5. __lubridate__: Garrett Grolemund, Hadley Wickham (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25. URL
  https://www.jstatsoft.org/v40/i03/.
  
6. __ggrepel__: Slowikowski K (2024). _ggrepel: Automatically Position Non-Overlapping Text Labels with 'ggplot2'_. R package version 0.9.5, <https://CRAN.R-project.org/package=ggrepel>.

7. __tibble__: Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.

8. __kableExtra__: Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0,
  <https://CRAN.R-project.org/package=kableExtra>.
  
9. __patchwork__: Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.2.0, <https://CRAN.R-project.org/package=patchwork>.

# References



